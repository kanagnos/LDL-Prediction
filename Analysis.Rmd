---
title: "LDLClassification"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Load packages
```{r libraries}
rm(list=ls())
require(tidyverse)
require(e1071)
require(caret)
require(xgboost)
require(h2o)
require(ggridges)
require(gridExtra)
require(keras)
require(kernlab)
require(janitor)
require(philentropy)
require(directlabels)
require(DiagrammeR)
```

# Set working dir
```{r setwd}
setwd(".")
```

# Definitions
```{r definitions}
NCEPlvl <- c("Optimal", "Near optimal", "Borderline high", "High", "Very high")
ESClvl <- c("LDL Cat 1", "LDL Cat 2", "LDL Cat 3", "LDL Cat 4", "LDL Cat 5", "LDL Cat 6")
```


# Functions
## Retrieve last value of a vector
```{r lastvalue}
lastValue <- function(x) { return( x[length(x)] ) }
```

## Convert a list from lapply to a dataframe
```{r fConvert_lapplyListToDataframe}
fConvert_lapplyListToDataframe <- function(lst) {
  DF = as.data.frame(do.call(rbind, lst))
}
```

## fClassifyLDLByNCEP
Function to classify LDL by NCEP category
```{r}
fClassNCEP <- function(vec) {
  res <- factor(cut(vec, breaks=c(0, 99, 129, 159, 189, Inf),
                              labels=c("Optimal", "Near Optimal-Above Optimal",
                                       "Borderline high", "High", "Very high"),
                              include.lowest =  T)
                         )
  levels(res) = NCEPlvl
  return(res)  
}

```

## fClassifyLDLByESC2019
Function to classify LDL by ESC 2019 category
```{r}
fClassESC <- function(vec) {
  res <- factor(cut(vec, breaks=c(0, 54, 69, 99, 115, 189, Inf),
                              labels=c("LDL Cat 1", "LDL Cat 2", "LDL Cat 3",
                                      "LDL Cat 4", "LDL Cat 5", "LDL Cat 6"),
                              include.lowest =  T)
                         )
  levels(res) = ESClvl
  return(res)  
}
```


## fPltRidge
Calculate median values, 2.5 and 97.5 quntiles and plot ggridges for the specified parameter
```{r fPltRidge}
fPltRidge <- function(param, pltMarg = c(0.1, -5, 0, 0),
                      textSize = 18, xAxishjust= 0.35,
                      hideYaxis = T) {
    dfTmp <- as.data.frame(
        rbind(dfKomTrain[,c("src", param)],
              dfKomTest[,c("src", param)],
              dfIndep1[,c("src", param)],
              dfIndep2[,c("src", param)]))
    
    # Set order of factor levels
    dfTmp$src <- factor(dfTmp$src,
                        levels=c("Independent2", "Independent1", "Test", "Train"))
    
    # Calculate median values
    median_values <- dfTmp %>% 
        group_by(src) %>%
        summarise(med=median(!!sym(param)), q2_5=quantile(!!sym(param), probs = 0.025),
                  q97_5=quantile(!!sym(param),probs = 0.975))
    # Create the plot
    if(hideYaxis) {
      ggplt <-
          ggplot(dfTmp, aes(x = !!sym(param), y = src, fill=factor(..quantile..))) + 
          stat_density_ridges(geom="density_ridges_gradient", calc_ecdf=T,
                              scale=1.2, quantile_lines = T,
                              quantiles=c(0.025, 0.50, 0.975)) +
          scale_fill_manual(name="Quartiles", values=c("gray15", "gray30", "gray60", "gray90")) +
          theme_light() +
          theme(legend.position = "none",
                plot.margin=unit(pltMarg, "cm"),
                axis.text.y=element_blank(),
                text = element_text(size=textSize),
                axis.title.x=element_text(hjust=xAxishjust)) +
          ylab("")
    } else {
        ggplt <-
          ggplot(dfTmp, aes(x = !!sym(param), y = src, fill=factor(..quantile..))) + 
          stat_density_ridges(geom="density_ridges_gradient", calc_ecdf=T,
                              scale=1.2, quantile_lines = T,
                              quantiles=c(0.025, 0.50, 0.975)) +
          scale_fill_manual(name="Quartiles", values=c("gray15", "gray30", "gray60", "gray90")) +
          theme_light() +
          theme(legend.position = "none",
                plot.margin=unit(pltMarg, "cm"),
                text = element_text(size=textSize),
                axis.title.x=element_text(hjust=xAxishjust)) +
          ylab("Data set")
      }
    
    return(list(plt=ggplt, mdn=median_values))
}
```


## fPltRidgeIndep
Calculate median values, 2.5 and 97.5 quntiles and plot ggridges for the specified parameter
for the Independent data sets 1 and 2 comparing the distributions of the whole data set (Indep1 or Indep2), and the respective Train and Test sets
```{r fPltRidgeIndep}
fPltRidgeIndep <- function(param, pltMarg = c(0.1, -5, 0, 0),
                      indep1or2, textSize = 18, xAxishjust= 0.35,
                      hideYaxis = T) {
  if(indep1or2==1) {
    dfTmp <- as.data.frame(
          rbind(dfIndep1Train[,c("trainOrTest", param)],
                dfIndep1Test[,c("trainOrTest", param)]))
    }  else if(indep1or2==2) {
      dfTmp <- as.data.frame(
          rbind(dfIndep2Train[,c("trainOrTest", param)],
                dfIndep2Test[,c("trainOrTest", param)]))
  }
    
    # Set order of factor levels
    dfTmp$trainOrTest <- factor(dfTmp$trainOrTest, levels=c("test", "train"))
    
    # Calculate median values
    median_values <- dfTmp %>% 
        group_by(trainOrTest) %>%
        summarise(med=median(!!sym(param)), q2_5=quantile(!!sym(param), probs = 0.025),
                  q97_5=quantile(!!sym(param),probs = 0.975))
    # Create the plot
    if(hideYaxis) {
      ggplt <-
          ggplot(dfTmp, aes(x = !!sym(param), y = trainOrTest, fill=factor(..quantile..))) + 
          stat_density_ridges(geom="density_ridges_gradient", calc_ecdf=T,
                              scale=1.2, quantile_lines = T,
                              quantiles=c(0.025, 0.50, 0.975)) +
          scale_fill_manual(name="Quartiles", values=c("gray15", "gray30", "gray60", "gray90")) +
          theme_light() +
          theme(legend.position = "none",
                plot.margin=unit(pltMarg, "cm"),
                axis.text.y=element_blank(),
                text = element_text(size=textSize),
                axis.title.x=element_text(hjust=xAxishjust)) +
          ylab("")
    } else {
        ggplt <-
          ggplot(dfTmp, aes(x = !!sym(param), y = trainOrTest, fill=factor(..quantile..))) + 
          stat_density_ridges(geom="density_ridges_gradient", calc_ecdf=T,
                              scale=1.2, quantile_lines = T,
                              quantiles=c(0.025, 0.50, 0.975)) +
          scale_fill_manual(name="Quartiles", values=c("gray15", "gray30", "gray60", "gray90")) +
          theme_light() +
          theme(legend.position = "none",
                plot.margin=unit(pltMarg, "cm"),
                text = element_text(size=textSize),
                axis.title.x=element_text(hjust=xAxishjust)) +
          ylab("Data set")
      }
    
    return(list(plt=ggplt, mdn=median_values))
}
```

## fSEE
Calculate the standard error of the estimate (SEE), when comparing it to measured values.
```{r fSEE}
fSEE <- function(prediction, measured) {
  prediction <- as.data.frame(prediction)
  measured <- as.data.frame(measured)
  n <- nrow(prediction)
  SEE <- sqrt(sum((prediction - measured)^2) / n)
  return(SEE)
}
```


## fAccur
Calculate confusion matrix and accuracy between experimental and predicted classification
```{r fACcur}
fAccur <- function(vecExper, vecPred) {
    n <- nrow(vecExper)
    cm <- table(vecExper, vecPred)
    accur <- sum(diag(cm)) / sum(cm)
    accurLow95CI <- accur - 1.96 * sqrt( (accur * (1 - accur)) / n)
    accurHigh95CI <- accur + 1.96 * sqrt( (accur * (1 - accur)) / n)
    return(list(confusionMatrix=cm, accuracy=accur, lowAccur=accurLow95CI,
                highAccur=accurHigh95CI))
}
```

## fFindOptimalKnn
Function to test a range of k values in Knn classification of LDL.
dfTrain is the training dataset, dfTest is the test data set,
vecTrainTrueClass is the correct classifications of the train data set,
vecTestTrueClass is the correct classifications of the test data set and
kRange is the range of k nearest neighbours to try.
The function will return a list with the maximum accuracy obtained and the corrresponding k value.
```{r fFindOptimalKnn}
fFindOptimalKnn <- function(dfTrain, dfTest, vecTrainTrueClass, vecTestTrueClass, kRange) {
    vecKnnAccur <- vector(mode="numeric", length=length(kRange)) # Vector to hold the accuracy values
      for(k in kRange) {
          LDLClassKnnPred <- #Train and predict the new classifications for the test data set
            class::knn(train = dfTrain,
                       test =  dfTest,
                       cl = vecTrainTrueClass,
                       k = k)
          LDLClassKnnConfMtrx<- table(vecTestTrueClass, LDLClassKnnPred) # Create the confusion matrix 
                                                                         #comparing the true and the
                                                                          #predicted classifications
          vecKnnAccur[k] <-  fAccur(vecTestTrueClass, LDLClassKnnPred)$accuracy
      }
    optimalAccur <- vecKnnAccur[which.max(vecKnnAccur)]# Find the maximum accuracy
    optimalK <- which.max(vecKnnAccur) # Find the k value for which the maximum accuracy was obtained.
    return(list(optimalK=optimalK, optimalAccuracy=optimalAccur))
}
```

## fDNNRegrGridSearch
Function to include in a loop to search for the best DNN architecture for regression prediction of LDL values from CHOL, HDL and TG.
```{r fDNNRegrGridSearch}
fDNNRegrGridSearch <- function(DF=dfKomTrain, noOfFolds=5, lstFolds=komTrainFolds,
                               hiddenLayers=rep(30, 6), activation="Rectifier",
                               noOfEpochs=100, samplesPerIter = -2) {
    cnt <- 1
    vecMSE <- vector(mode="numeric", length=kFolds)

    for(i in 1:noOfFolds) {
        x <- lstFolds[[i]]
        trainFold <- DF[-x, ]
        testFold <- DF[x, ]
        LDL_dnn = h2o.deeplearning(y="LDLd",
                                   training_frame =
                                     as.h2o(trainFold[ ,c("CHOLScaled","HDLScaled",
                                                          "TGScaled", "LDLd")]),
                                   activation = activation,
                                   hidden = hiddenLayers,
                                   epochs = noOfEpochs,
                                   train_samples_per_iteration = samplesPerIter)
        LDL_dnn_Pred <- h2o.predict(LDL_dnn, newdata =
                                      as.h2o(testFold[,c("CHOLScaled", "HDLScaled",
                                                         "TGScaled")]))
        LDL_dnn_Pred <- as.vector(LDL_dnn_Pred)
        mse <- sum((LDL_dnn_Pred - testFold$LDLd)^2) / nrow(testFold)
        vecMSE[cnt] <- mse
        cnt <- cnt + 1
    }
  return(min(vecMSE))    
}
```

## fDNNClassGridSearch
Function to include in a loop to search for the best DNN architecture for regression prediction of LDL levels from CHOL, HDL and TG.
```{r fDNNClassGridSearch}
fDNNClassGridSearch <- function(DF=dfKomTrain, LDLclass="NCEPd", LDLlvl=NCEPlvl, noOfFolds=5,
                                lstFolds=komTrainFolds,  hiddenLayers=rep(30, 6),
                                activation="Rectifier", noOfEpochs=100,
                                samplesPerIter = -2) {
    cnt <- 1
    vecAccur <- vector(mode="numeric", length=noOfFolds)
    for(i in 1:noOfFolds) {
        x <- lstFolds[[i]]
        trainFold <- DF[-x, ]
        testFold  <- DF[x, ]
        LDL_dnn = h2o.deeplearning(y=LDLclass,
                    training_frame =
                      as.h2o(trainFold[ ,c("CHOLScaled", "HDLScaled", "TGScaled", LDLclass)]),
                                   activation = activation,
                                   hidden = hiddenLayers,
                                   epochs = noOfEpochs,
                                   train_samples_per_iteration = samplesPerIter)
        LDL_dnn_Pred <- h2o.predict(LDL_dnn, newdata =
                                      as.h2o(testFold[,c("CHOLScaled", "HDLScaled", "TGScaled")]))
        LDL_dnn_Pred <- as.data.frame(LDL_dnn_Pred)
        LDL_dnn_Pred$predict <- factor(LDL_dnn_Pred$predict, levels=LDLlvl)
        testFold[, LDLclass] <- factor(testFold[, LDLclass], levels=LDLlvl)
        accur <- fAccur(testFold[, LDLclass], LDL_dnn_Pred$predict)$accuracy
        vecAccur[cnt] <- accur
        cnt <- cnt + 1
    }
  return(max(vecAccur))    
}
```

##fJSD
Calculate Jensen-Shannon divergence between the same parameter of different data sets. This works only for two distributions. As arguments we give the two data frames and the parameter (CHOL, HDL or TG)
```{r}
fJSD <- function(DF1=dfKomTrain, DF2=dfKomTest, param="CHOL") {
  vec1 <- DF1[, param]; vec2 <- DF2[, param]
  #Calculate the frequencies of vec1
  df1Freqs <- as.data.frame(janitor::tabyl(vec1))
  #The tabyl command gives a data frame with not only the frequencies but also the
  #percentages. Remove this column
  df1Freqs$percent <- NULL
  #Change column names
  colnames(df1Freqs) <- c("Param", "vec1Freq")
  #The same as above for vec2
  df2Freqs <- as.data.frame(janitor::tabyl(vec2))
  df2Freqs$percent <- NULL
  colnames(df2Freqs) <- c("Param", "vec2Freq")
  
  #Merge the two frequency data frames by the "Param" column.
  #When a Param value does not exist in one of the data frames, an NA is
  #inserted
  dfFreqs <- merge(df1Freqs, df2Freqs, by="Param", all.x=T, all.y = T)
  colnames(dfFreqs) <- c("Param", "vec1", "vec2")
  dfFreqs[is.na(dfFreqs)] <- 0#Replace NA with zeros.
  
  #Calc the probabilities of vec1 and vec2 frequencies. They should sum to 1.
  dfFreqs$vec1Prob <- dfFreqs$vec1 / sum(dfFreqs$vec1)
  vec1ProbSum <- sum(dfFreqs$vec1Prob)
  dfFreqs$vec2Prob <- dfFreqs$vec2 / sum(dfFreqs$vec2)
  vec2ProbSum <- sum(dfFreqs$vec2Prob)
  
  JSDres <- philentropy::JSD(rbind(dfFreqs$vec1Prob, dfFreqs$vec2Prob))
  return(list(JSD=JSDres, freq1=df1Freqs, freq2=df2Freqs,
              freqs=dfFreqs, vec1PSum=vec1ProbSum, vec2PSum=vec2ProbSum))
}
```

# Load
## Training, test, Independent 1 and 2 data sets. Also independent 1 and 2 split train and test data sets
```{r load data sets}
dfKomTrain <- read.csv("dfKomTrain.csv", header=T, sep=",")
dfKomTrain[,c("NCEPd", "NCEPf", "NCEPn")] <-
    lapply(dfKomTrain[,c("NCEPd", "NCEPf", "NCEPn")], factor, levels=NCEPlvl)
dfKomTrain[,c("ESCd", "ESCf", "ESCn")] <-
    lapply(dfKomTrain[,c("ESCd", "ESCf", "ESCn")], factor, levels=ESClvl)

dfKomTest  <- read.csv("dfKomTest.csv",  header=T, sep=",")
dfKomTest[,c("NCEPd", "NCEPf", "NCEPn")] <-
    lapply(dfKomTest[,c("NCEPd", "NCEPf", "NCEPn")], factor, levels=NCEPlvl)
dfKomTest[,c("ESCd", "ESCf", "ESCn")] <-
    lapply(dfKomTest[,c("ESCd", "ESCf", "ESCn")], factor, levels=ESClvl)

dfIndep1 <- read.csv("dfIndep1.csv", header=T, sep=",")
dfIndep1[,c("NCEPd", "NCEPf", "NCEPn")] <-
    lapply(dfIndep1[,c("NCEPd", "NCEPf", "NCEPn")], factor, levels=NCEPlvl)
dfIndep1[,c("ESCd", "ESCf", "ESCn")] <-
    lapply(dfIndep1[,c("ESCd", "ESCf", "ESCn")], factor, levels=ESClvl)

dfIndep2 <- read.csv("dfIndep2.csv",     header=T, sep=",")
dfIndep2[,c("NCEPd", "NCEPf", "NCEPn")] <-
    lapply(dfIndep2[,c("NCEPd", "NCEPf", "NCEPn")], factor, levels=NCEPlvl)
dfIndep2[,c("ESCd", "ESCf", "ESCn")] <-
    lapply(dfIndep2[,c("ESCd", "ESCf", "ESCn")], factor, levels=ESClvl)

dfIndep1Train <- read.csv("dfIndep1Train.csv", header=T, sep=",")
dfIndep1Train[,c("NCEPd", "NCEPf", "NCEPn")] <-
    lapply(dfIndep1Train[,c("NCEPd", "NCEPf", "NCEPn")], factor, levels=NCEPlvl)
dfIndep1Train[,c("ESCd", "ESCf", "ESCn")] <-
    lapply(dfIndep1Train[,c("ESCd", "ESCf", "ESCn")], factor, levels=ESClvl)


dfIndep1Test <- read.csv("dfIndep1Test.csv", header=T, sep=",")
dfIndep1Test[,c("NCEPd", "NCEPf", "NCEPn")] <-
    lapply(dfIndep1Test[,c("NCEPd", "NCEPf", "NCEPn")], factor, levels=NCEPlvl)
dfIndep1Test[,c("ESCd", "ESCf", "ESCn")] <-
    lapply(dfIndep1Test[,c("ESCd", "ESCf", "ESCn")], factor, levels=ESClvl)

dfIndep2Train <- read.csv("dfIndep2Train.csv", header=T, sep=",")
dfIndep2Train[,c("NCEPd", "NCEPf", "NCEPn")] <-
    lapply(dfIndep2Train[,c("NCEPd", "NCEPf", "NCEPn")], factor, levels=NCEPlvl)
dfIndep2Train[,c("ESCd", "ESCf", "ESCn")] <-
    lapply(dfIndep2Train[,c("ESCd", "ESCf", "ESCn")], factor, levels=ESClvl)

dfIndep2Test <- read.csv("dfIndep2Test.csv", header=T, sep=",")
dfIndep2Test[,c("NCEPd", "NCEPf", "NCEPn")] <-
    lapply(dfIndep2Test[,c("NCEPd", "NCEPf", "NCEPn")], factor, levels=NCEPlvl)
dfIndep2Test[,c("ESCd", "ESCf", "ESCn")] <-
    lapply(dfIndep2Test[,c("ESCd", "ESCf", "ESCn")], factor, levels=ESClvl)
```

## k-cross validations sets
```{r k-cross val sets}
komTrainFolds <- readRDS(file="komTrainFolds.rds")
```

# ------------------------
# 1.Density ridges and medians

# Add a column in all 4 whole data sets describing the data source (Train, Test, Indep1, Indep2)
```{r addDataSourceCol}
dfKomTrain$src <- "Train"
dfKomTest$src <- "Test"
dfIndep1$src <- "Independent1"
dfIndep2$src <- "Independent2"
```

# Add a column to dfIndep1 Train and Test and dfIndep2 Train and Test to signify if it is training or test
```{r addTrainTestCol}
dfIndep1Train$trainOrTest <- "train"
dfIndep1Test$trainOrTest <- "test"
dfIndep2Train$trainOrTest <- "train"
dfIndep2Test$trainOrTest <- "test"
```

## ...Figure S1...
### For whole data sets
```{r FigS1}
CHOLmedian <- fPltRidge(param="CHOL", hideYaxis = F)$mdn
HDLmedian <- fPltRidge(param="HDL", pltMarg = c(0.1, -7, 0, 0))$mdn
TGmedian <- fPltRidge(param="TG", pltMarg = c(0.1, -14, 0, 0) )$mdn
LDLdMedian <- fPltRidge(param="LDLd", pltMarg = c(0.1, -1, 0, 0))$mdn

ggpltCHOL <- fPltRidge(param="CHOL", hideYaxis = F)$plt
ggpltHDL <- fPltRidge(param="HDL", pltMarg = c(0.1, -7, 0, 0))$plt
ggpltTG <- fPltRidge(param="TG", pltMarg = c(0.1, -14, 0, 0) )$plt
ggpltLDLd <- fPltRidge(param="LDLd", pltMarg = c(0.1, -1, 0, 0))$plt

figureS1 <- 
  grid.arrange(ggpltCHOL, ggpltHDL, ggpltTG, ggpltLDLd, ncol=4)

rm(CHOLmedian, HDLmedian, TGmedian, LDLdMedian)
rm(ggpltCHOL, ggpltHDL, ggpltTG, ggpltLDLd)
rm(figureS1)
```

## ...Figure S2...
### Independent data set 1 split into training and test
```{r FigS2}
ggpltCHOLIndep1 <- fPltRidgeIndep(param = "CHOL", indep1or2 = 1, hideYaxis = F,
                                  pltMarg = c(0.1, 0, 0, 0))$plt
ggpltHDLIndep1 <- fPltRidgeIndep(param = "HDL", indep1or2 = 1, hideYaxis = T,
                                 pltMarg = c(0.1, 0, 0, 0))$plt
ggpltTGIndep1 <- fPltRidgeIndep(param = "TG", indep1or2 = 1, hideYaxis = T,
                                pltMarg = c(0.1, 0, 0, 0))$plt
ggpltLDLdIndep1 <- fPltRidgeIndep(param = "LDLd", indep1or2 = 1, hideYaxis = T,
                                  pltMarg = c(0.1, 0, 0, 0))$plt
figureS2 <- grid.arrange(ggpltCHOLIndep1, ggpltHDLIndep1, ggpltTGIndep1,
                         ggpltLDLdIndep1, ncol=4)
rm(ggpltCHOLIndep1, ggpltHDLIndep1, ggpltTGIndep1, ggpltLDLdIndep1)
rm(figureS2)
```

## ...Figure S3...
####Z Independent data set 2 split into training and test
```{r FigS3}
ggpltCHOLIndep2 <- fPltRidgeIndep(param = "CHOL", indep1or2 = 2, hideYaxis = F,
                                  pltMarg = c(0.1, 0, 0, 0))$plt
ggpltHDLIndep2 <- fPltRidgeIndep(param = "HDL", indep1or2 = 2, hideYaxis = T,
                                 pltMarg = c(0.1, 0, 0, 0))$plt
ggpltTGIndep2 <- fPltRidgeIndep(param = "TG", indep1or2 = 2, hideYaxis = T,
                                pltMarg = c(0.1, 0, 0, 0))$plt
ggpltLDLdIndep2 <- fPltRidgeIndep(param = "LDLd", indep1or2 = 2, hideYaxis = T,
                                  pltMarg = c(0.1, 0, 0, 0))$plt
figureS3 <- grid.arrange(ggpltCHOLIndep2, ggpltHDLIndep2, ggpltTGIndep2,
                         ggpltLDLdIndep2, ncol=4)
rm(ggpltCHOLIndep2, ggpltHDLIndep2, ggpltTGIndep2, ggpltLDLdIndep2)
rm(figureS3)
```

## Remove source columns
```{r removeSourceCols}
dfKomTest$src <- dfKomTrain$src <- dfIndep1$src <- dfIndep2$src <- NULL
dfIndep1Test$trainOrTest <- dfIndep1Train$trainOrTest <-
  dfIndep2Train$trainOrTest <- dfIndep2Test$trainOrTest <- NULL
```

# ------------------------
# 2.JS divergence
## Calc JSD for the pairs of data sets given in dataSet1 and dataSet2 and for the 3 parameters (CHOL, HDL, TG)
```{r, message=F}
dataSet1 <- c("dfKomTrain", "dfKomTrain", "dfKomTrain",
              "dfIndep1", "dfIndep2", "dfIndep1")
dataSet2 <- c("dfKomTest", "dfIndep1", "dfIndep2",
              "dfIndep1Test", "dfIndep2Test", "dfIndep2")
params <- c("CHOL", "HDL", "TG")

dfJSD <- data.frame(dataSet1=character(5), dataSet2=character(5),
                    CHOL=numeric(5), HDL=numeric(5), TG=numeric(5))
for(datasetIdx in 1:length(dataSet1))   {
    for(paramIdx in 1:length(params)) {
        df1 <- dataSet1[[datasetIdx]]
        df2 <- dataSet2[[datasetIdx]]
        param <- params[paramIdx]
        JSDval <- fJSD(DF1=get(df1), DF2=get(df2), param)$JSD
        #cat(df1, ", ", df2, ", ", param, ", ", JSDval, "\n")
        dfJSD[datasetIdx, c("dataSet1", "dataSet2")] <- c(df1, df2)
        dfJSD[datasetIdx, param] <- round(JSDval, 2)
    }
}
dfJSD$JSDMulti <- dfJSD$CHOL + dfJSD$HDL + dfJSD$TG
rm(dataset1, dataset2, params, dfJSD)
```

# ------------------------
# 3. LDLf
## Estimation SEE
```{r LDLf_SEE}
LDLfTestRegrSEE <- fSEE(dfKomTest$LDLf, dfKomTest$LDLd)# SEE for test data set
cor.test(dfKomTest$LDLf, dfKomTest$LDLd)# Corr coef for test data set
LDLfTestRegrSEE <- formatC(LDLfTestRegrSEE, digits=2, format="f")
LDLfIndep1RegrSEE <- fSEE(dfIndep1$LDLf, dfIndep1$LDLd)# SEE for PGNA
cor.test(dfIndep1$LDLf, dfIndep1$LDLd)# Corr coef for indep1 data set
LDLfIndep1RegrSEE <- formatC(LDLfIndep1RegrSEE, digits=2, format="f")
cor.test(dfIndep2$LDLf, dfIndep2$LDLd)# Corr coef for indep1 data set
LDLfIndep2RegrSEE <- fSEE(dfIndep2$LDLf, dfIndep2$LDLd)# SEE Democritus
LDLfIndep2RegrSEE <- formatC(LDLfIndep2RegrSEE, digits=2, format="f")
rm(LDLfTestRegrSEE, LDLfIndep1RegrSEE, LDLfIndep2RegrSEE)
```

## Residuals for LDLf
```{r}
dfTestRsdl <- data.frame(method="LDLf", rsdl = dfKomTest$LDLd - dfKomTest$LDLf)
dfIndep1Rsdl <- data.frame(method="LDLf", rsdl = dfIndep1$LDLd - dfIndep1$LDLf)
dfIndep2Rsdl <- data.frame(method="LDLf", rsdl = dfIndep2$LDLd - dfIndep2$LDLf)
```

## NCEP Classification accuracy
```{r NCEPClassAccur}
# For test data set
LDLfTestNCEP_CF <- caret::confusionMatrix(dfKomTest$NCEPd, dfKomTest$NCEPf)
LDLfTestNCEP_CF$table
vecLDLfTestNCEPAccur <-c( 
  formatC(round(LDLfTestNCEP_CF$overall["Accuracy"], 2), digits=2, format="f"),
  formatC(round(LDLfTestNCEP_CF$overall["AccuracyLower"], 2), digits=2, format="f"),
  formatC(round(LDLfTestNCEP_CF$overall["AccuracyUpper"], 2), digits=2, format="f"))
# For Indep1 data set
LDLfIndep1NCEP_CF <- caret::confusionMatrix(dfIndep1$NCEPd, dfIndep1$NCEPf)
vecLDLfIndep1NCEPAccur <-c( 
  formatC(round(LDLfIndep1NCEP_CF$overall["Accuracy"], 2), digits=2, format="f"),
  formatC(round(LDLfIndep1NCEP_CF$overall["AccuracyLower"], 2), digits=2, format="f"),
  formatC(round(LDLfIndep1NCEP_CF$overall["AccuracyUpper"], 2), digits=2, format="f"))
# For Indep2 data set
LDLfIndep2NCEP_CF <- caret::confusionMatrix(dfIndep2$NCEPd, dfIndep2$NCEPf)
vecLDLfIndep2NCEPAccur <-c( 
  formatC(round(LDLfIndep2NCEP_CF$overall["Accuracy"], 2), digits=2, format="f"),
  formatC(round(LDLfIndep2NCEP_CF$overall["AccuracyLower"], 2), digits=2, format="f"),
  formatC(round(LDLfIndep2NCEP_CF$overall["AccuracyUpper"], 2), digits=2, format="f"))
```

## ESC classification accuracy
```{r ESCClassAccur}
LDLfTestESC_CF <- caret::confusionMatrix(dfKomTest$ESCd, dfKomTest$ESCf)
LDLfTestESC_CF$table
vecLDLfTestESCAccur <-c( 
  formatC(round(LDLfTestESC_CF$overall["Accuracy"], 2), digits=2, format="f"),
  formatC(round(LDLfTestESC_CF$overall["AccuracyLower"], 2), digits=2, format="f"),
  formatC(round(LDLfTestESC_CF$overall["AccuracyUpper"], 2), digits=2, format="f"))
# For Indep1 data set
LDLfIndep1ESC_CF <- caret::confusionMatrix(dfIndep1$ESCd, dfIndep1$ESCf)
vecLDLfIndep1ESCAccur <-c( 
  formatC(round(LDLfIndep1ESC_CF$overall["Accuracy"], 2), digits=2, format="f"),
  formatC(round(LDLfIndep1ESC_CF$overall["AccuracyLower"], 2), digits=2, format="f"),
  formatC(round(LDLfIndep1ESC_CF$overall["AccuracyUpper"], 2), digits=2, format="f"))
# For Indep2 data set
LDLfIndep2ESC_CF <- caret::confusionMatrix(dfIndep2$ESCd, dfIndep2$ESCf)
vecLDLfIndep2ESCAccur <-c( 
  formatC(round(LDLfIndep2ESC_CF$overall["Accuracy"], 2), digits=2, format="f"),
  formatC(round(LDLfIndep2ESC_CF$overall["AccuracyLower"], 2), digits=2, format="f"),
  formatC(round(LDLfIndep2ESC_CF$overall["AccuracyUpper"], 2), digits=2, format="f"))
```

## Data frame of LDLf NCEP and ESC accuracies
```{r dfLDLfAccur}
dfLDLfAccur <- 
  data.frame(cbind(
    vecLDLfTestNCEPAccur, vecLDLfIndep1NCEPAccur, vecLDLfIndep2NCEPAccur,
    vecLDLfTestESCAccur, vecLDLfIndep1ESCAccur, vecLDLfIndep2ESCAccur))
colnames(dfLDLfAccur) <- c("Test NCEP", "Indep1 NCEP", "Indep2 NCEP",
                          "Test ESC",  "Indep1 ESC",  "Indep2 ESC")
```

# ------------------------
# 4. LDLn
## Estimation SEE
```{r}
LDLnTestRegrSEE <- fSEE(dfKomTest$LDLn, dfKomTest$LDLd)# SEE for test data set
LDLnTestRegrSEE <- formatC(LDLnTestRegrSEE, digits=2, format="f")
LDLnIndep1RegrSEE <- fSEE(dfIndep1$LDLn, dfIndep1$LDLd)# SEE for PGNA
LDLnIndep1RegrSEE <- formatC(LDLnIndep1RegrSEE, digits=2, format="f")
LDLnIndep2RegrSEE <- fSEE(dfIndep2$LDLn, dfIndep2$LDLd)# SEE Democritus
LDLnIndep2RegrSEE <- formatC(LDLnIndep2RegrSEE, digits=2, format="f")
rm(LDLnTestRegrSEE, LDLnIndep1RegrSEE, LDLnIndep2RegrSEE)
```

## Residuals for LDLn
```{r}
dfTestRsdlTmp <- data.frame(method="LDLn", rsdl=(dfKomTest$LDLd - dfKomTest$LDLn))
dfTestRsdl <- as.data.frame(rbind(dfTestRsdl, dfTestRsdlTmp))
rm(dfTestRsdlTmp)

dfIndep1RsdlTmp <- data.frame(method="LDLn", rsdl=(dfIndep1$LDLd - dfIndep1$LDLn))
dfIndep1Rsdl <- as.data.frame(rbind(dfIndep1Rsdl, dfIndep1RsdlTmp))
rm(dfIndep1RsdlTmp)

dfIndep2RsdlTmp <- data.frame(method="LDLn", rsdl=(dfIndep2$LDLd - dfIndep2$LDLn))
dfIndep2Rsdl <- as.data.frame(rbind(dfIndep2Rsdl, dfIndep2RsdlTmp))
rm(dfIndep2RsdlTmp)
```

## Remove temp variables
```{r}
rm(list=ls(pattern="test*"))
rm(list=ls(pattern="indep*"))
rm(list=ls(pattern="vecLDLfNCEP"))
rm(list=ls(pattern="vecLDLfESC"))
```

## NCEP Classification accuracy
```{r}
# For test data set
LDLnTestNCEP_CF <- caret::confusionMatrix(dfKomTest$NCEPd, dfKomTest$NCEPn)
LDLnTestNCEP_CF$table
write.table(LDLnTestNCEP_CF$table, file="LDLnTestNCEP_CF.txt", sep=",")
vecLDLnTestNCEPAccur <-c( 
  formatC(round(LDLnTestNCEP_CF$overall["Accuracy"], 2), digits=2, format="f"),
  formatC(round(LDLnTestNCEP_CF$overall["AccuracyLower"], 2), digits=2, format="f"),
  formatC(round(LDLnTestNCEP_CF$overall["AccuracyUpper"], 2), digits=2, format="f"))
# For Indep1 data set
LDLnIndep1NCEP_CF <- caret::confusionMatrix(dfIndep1$NCEPd, dfIndep1$NCEPn)
vecLDLnIndep1NCEPAccur <-c( 
  formatC(round(LDLnIndep1NCEP_CF$overall["Accuracy"], 2), digits=2, format="f"),
  formatC(round(LDLnIndep1NCEP_CF$overall["AccuracyLower"], 2), digits=2, format="f"),
  formatC(round(LDLnIndep1NCEP_CF$overall["AccuracyUpper"], 2), digits=2, format="f"))
# For Indep2 data set
LDLnIndep2NCEP_CF <- caret::confusionMatrix(dfIndep2$NCEPd, dfIndep2$NCEPn)
vecLDLnIndep2NCEPAccur <-c( 
  formatC(round(LDLnIndep2NCEP_CF$overall["Accuracy"], 2), digits=2, format="f"),
  formatC(round(LDLnIndep2NCEP_CF$overall["AccuracyLower"], 2), digits=2, format="f"),
  formatC(round(LDLnIndep2NCEP_CF$overall["AccuracyUpper"], 2), digits=2, format="f"))
```

## ESC classification accuracy
```{r}
LDLnTestESC_CF <- caret::confusionMatrix(dfKomTest$ESCd, dfKomTest$ESCn)
LDLnTestESC_CF$table
vecLDLnTestESCAccur <-c( 
  formatC(round(LDLnTestESC_CF$overall["Accuracy"], 2), digits=2, format="f"),
  formatC(round(LDLnTestESC_CF$overall["AccuracyLower"], 2), digits=2, format="f"),
  formatC(round(LDLnTestESC_CF$overall["AccuracyUpper"], 2), digits=2, format="f"))
# For Indep1 data set
LDLnIndep1ESC_CF <- caret::confusionMatrix(dfIndep1$ESCd, dfIndep1$ESCn)
vecLDLnIndep1ESCAccur <-c( 
  formatC(round(LDLnIndep1ESC_CF$overall["Accuracy"], 2), digits=2, format="f"),
  formatC(round(LDLnIndep1ESC_CF$overall["AccuracyLower"], 2), digits=2, format="f"),
  formatC(round(LDLnIndep1ESC_CF$overall["AccuracyUpper"], 2), digits=2, format="f"))
# For Indep2 data set
LDLnIndep2ESC_CF <- caret::confusionMatrix(dfIndep2$ESCd, dfIndep2$ESCn)
vecLDLnIndep2ESCAccur <-c( 
  formatC(round(LDLnIndep2ESC_CF$overall["Accuracy"], 2), digits=2, format="f"),
  formatC(round(LDLnIndep2ESC_CF$overall["AccuracyLower"], 2), digits=2, format="f"),
  formatC(round(LDLnIndep2ESC_CF$overall["AccuracyUpper"], 2), digits=2, format="f"))
```

## Data frame of LDLn NCEP and ESC Accuracy
```{r}
dfLDLnAccur <- 
  data.frame(cbind(
    vecLDLnTestNCEPAccur, vecLDLnIndep1NCEPAccur, vecLDLnIndep2NCEPAccur,
    vecLDLnTestESCAccur, vecLDLnIndep1ESCAccur, vecLDLnIndep2ESCAccur))
colnames(dfLDLnAccur) <- c("Test NCEP", "Indep1 NCEP", "Indep2 NCEP",
                          "Test ESC",  "Indep1 ESC",  "Indep2 ESC")
```

## Clean up
```{r}
rm(list=ls(pattern="vec*"))
rm(list=ls(pattern="LDLf*"))
```

# -----------------------
# 5. Radial Basis Kernel SVM
## Regression
### Tune on Train sata set
The code chunk will not be run, but the model will be loaded from file in the next chunk.
```{r, eval=F}
radSVM_TrainRegr <- caret::train(form = LDLd ~ CHOLScaled + TGScaled +
                                   HDLScaled,
                                   data = dfKomTrain,
                                   method = "svmRadial")
```

### Read radSVM_TrainRegr from file
```{r}
radSVM_TrainRegr <- readRDS(file="./radSVM_TrainRegr.rds")
radSVM_TrainRegr
```

#### Predict test data using the training on the train data set
```{r}
radSVMTestRegrPred <- predict(radSVM_TrainRegr, newdata = dfKomTest, se=T)
radSVMTestRegrSEE <- round(fSEE(radSVMTestRegrPred, dfKomTest$LDLd), 1)
```

##### Predict class of LDL
```{r}
radSVMTestClassNCEP <- fClassNCEP(radSVMTestRegrPred)
caret::confusionMatrix(dfKomTest$NCEPd, radSVMTestClassNCEP)
radSVMTestClassESC <- fClassESC(radSVMTestRegrPred)
caret::confusionMatrix(dfKomTest$ESCd, radSVMTestClassESC)
```

#### Predict indep1 using train data set
```{r}
radSVMIndep1RegrPred <- predict(radSVM_TrainRegr, newdata = dfIndep1, se = T)
radSVMIndep1RegrSEE <- round(fSEE(radSVMIndep1RegrPred, dfIndep1$LDLd), 1)
```

##### Predict class of LDL
```{r}
radSVMIndep1ClassNCEP <- fClassNCEP(radSVMIndep1RegrPred)
caret::confusionMatrix(dfIndep1$NCEPd, radSVMIndep1ClassNCEP)
radSVMIndep1ClassESC <- fClassESC(radSVMIndep1RegrPred)
caret::confusionMatrix(dfIndep1$ESCd, radSVMIndep1ClassESC)
```


#### Predict indep2 
```{r}
radSVMIndep2RegrPred <- predict(radSVM_TrainRegr, newdata = dfIndep2)
radSVMIndep2RegrSEE <- round(fSEE(radSVMIndep2RegrPred, dfIndep2$LDLd), 1)
```

##### Predict class of LDL
```{r}
radSVMIndep2ClassNCEP <- fClassNCEP(radSVMIndep2RegrPred)
caret::confusionMatrix(dfIndep2$NCEPd, radSVMIndep2ClassNCEP)
radSVMIndep2ClassESC <- fClassESC(radSVMIndep2RegrPred)
caret::confusionMatrix(dfIndep2$ESCd, radSVMIndep2ClassESC)
```

#### Residuals for radSVM
```{r}
dfTestRsdlTmp <- data.frame(method="radSVM",
                            rsdl=(dfKomTest$LDLd - radSVMTestRegrPred))
dfTestRsdl <- as.data.frame(rbind(dfTestRsdl, dfTestRsdlTmp))
rm(dfTestRsdlTmp)

dfIndep1RsdlTmp <- data.frame(method="radSVM",
                              rsdl=(dfIndep1$LDLd - radSVMIndep1RegrPred))
dfIndep1Rsdl <- as.data.frame(rbind(dfIndep1Rsdl, dfIndep1RsdlTmp))
rm(dfIndep1RsdlTmp)

dfIndep2RsdlTmp <- data.frame(method="radSVM",
                              rsdl=(dfIndep2$LDLd - radSVMIndep2RegrPred))
dfIndep2Rsdl <- as.data.frame(rbind(dfIndep2Rsdl, dfIndep2RsdlTmp))
rm(dfIndep2RsdlTmp)
```

### Tune on independent data sets
##### Tune on Indep1 test data set
```{r}
radSVMIndep1RegrTrain <- caret::train(form = LDLd ~
                                        CHOLScaled + TGScaled + HDLScaled,
                                   data = dfIndep1Train,
                                   method = "svmRadial")
radSVMIndep1RegrTrain
```

#### Predict indep1 test
```{r}
radSVMIndep1testRegrPred <- predict(radSVMIndep1RegrTrain,
                                    newdata = dfIndep1Test)
radSVMIndep1testRegrSEE <- round(fSEE(radSVMIndep1testRegrPred,
                                      dfIndep1Test$LDLd), 1)
```

###### Predict class of LDL
```{r}
radSVMIndep1testClassNCEP <- fClassNCEP(radSVMIndep1testRegrPred)
caret::confusionMatrix(dfIndep1Test$NCEPd, radSVMIndep1testClassNCEP)
radSVMIndep1testClassESC <- fClassESC(radSVMIndep1testRegrPred)
caret::confusionMatrix(dfIndep1Test$ESCd, radSVMIndep1testClassESC)
```

### Tune on Indep2 test data set
```{r}
radSVMIndep2RegrTrain <- caret::train(form = LDLd ~
                                        CHOLScaled + TGScaled + HDLScaled,
                                   data = dfIndep2Train,
                                   method = "svmRadial")
radSVMIndep2RegrTrain
```

#### Predict indep2 test
```{r}
radSVMIndep2testRegrPred <- predict(radSVMIndep2RegrTrain,
                                    newdata = dfIndep2Test)
radSVMIndep2testRegrSEE <- round(fSEE(radSVMIndep2testRegrPred,
                                      dfIndep2Test$LDLd), 1)
```

##### Predict class of LDL
```{r}
radSVMIndep2testClassNCEP <- fClassNCEP(radSVMIndep2testRegrPred)
caret::confusionMatrix(dfIndep2Test$NCEPd, radSVMIndep2testClassNCEP)
radSVMIndep2testClassESC <- fClassESC(radSVMIndep2testRegrPred)
caret::confusionMatrix(dfIndep2Test$ESCd, radSVMIndep2testClassESC)
```

#### Vector of radial SVM regression SEE
```{r}
vecRadSVM_RegrSEE <- c(radSVMTestRegrSEE, radSVMIndep1RegrSEE,
                       radSVMIndep2RegrSEE,
                       radSVMIndep1testRegrSEE,
                       radSVMIndep2testRegrSEE)
names(vecRadSVM_RegrSEE) <- c("Test SEE", "Indep1 SEE on Train",
                              "Indep2 SEE on Train",
                             "Indep1 SEE",  "Indep2 SEE")
vecRadSVM_RegrSEE
```

### Clean up
```{r}
rm(list=ls(pattern = "radSVM*"))
rm(list=ls(pattern = "vecRadSVM*"))
```

# -----------------------
# 6. DART XGBoost
## Regression
### Tune on Train data set
```{r, eval=F}
drtXGB_TrainRegr <- caret::train(form = LDLd ~ CHOL + TG + HDL,
                                   data = dfKomTrain,
                                   method = "xgbDART")
```

### Load drtXGB_TrainRegr
```{r}
drtXGB_TrainRegr <- readRDS(file="./drtXGB_Train.rds")
drtXGB_TrainRegr
```

### Plot trees
```{r}
xgb.plot.tree(model=drtXGB_TrainRegr$finalModel, trees=4)
```

#### Predict test data using Train
```{r}
drtXGBTestRegrPred <- predict(drtXGB_TrainRegr, newdata = dfKomTest)
drtXGBTestRegrSEE <- fSEE(drtXGBTestRegrPred, dfKomTest$LDLd)
```

##### Predict class of LDL
```{r}
drtXGBTestClassNCEP <- fClassNCEP(drtXGBTestRegrPred)
caret::confusionMatrix(dfKomTest$NCEPd, drtXGBTestClassNCEP)
drtXGBTestClassESC <- fClassESC(drtXGBTestRegrPred)
caret::confusionMatrix(dfKomTest$ESCd, drtXGBTestClassESC)
```

#### Predict indep1 using Train
```{r}
drtXGBIndep1RegrPred <- predict(drtXGB_TrainRegr, newdata = dfIndep1)
drtXGBIndep1RegrSEE <- fSEE(drtXGBIndep1RegrPred, dfIndep1$LDLd)
```

##### Predict class of LDL
```{r}
drtXGBIndep1ClassNCEP <- fClassNCEP(drtXGBIndep1RegrPred)
caret::confusionMatrix(dfIndep1$NCEPd, drtXGBIndep1ClassNCEP)
drtXGBIndep1ClassESC <- fClassESC(drtXGBIndep1RegrPred)
caret::confusionMatrix(dfIndep1$ESCd, drtXGBIndep1ClassESC)
```

#### Predict indep2 using Train
```{r}
drtXGBIndep2RegrPred <- predict(drtXGB_TrainRegr, newdata = dfIndep2)
drtXGBIndep2RegrSEE <- fSEE(drtXGBIndep2RegrPred, dfIndep2$LDLd)
```

##### Predict class of LDL
```{r}
drtXGBIndep2ClassNCEP <- fClassNCEP(drtXGBIndep2RegrPred)
caret::confusionMatrix(dfIndep2$NCEPd, drtXGBIndep2ClassNCEP)
drtXGBIndep2ClassESC <- fClassESC(drtXGBIndep2RegrPred)
caret::confusionMatrix(dfIndep2$ESCd, drtXGBIndep2ClassESC)
```

### Tune on independent data sets
##### Tune on Indep1 test data set
```{r, eval=F}
drtXGBIndep1TrainRegr <- caret::train(form = LDLd ~ CHOL + TG + HDL,
                                   data = dfIndep1Train,
                                   method = "xgbDART")
```

#### Load drtXGBIndep1TrainRegr
```{r}
drtXGBIndep1TrainRegr <-
  readRDS(file="./drtXGBIndep1TrainRegr.rds")
```

##### Predict indep1 test
```{r}
drtXGBIndep1TestRegrPred <- predict(drtXGBIndep1TrainRegr,
                                     newdata = dfIndep1Test)
drtXGB_Indep1TestRegrSEE <- fSEE(drtXGBIndep1TestRegrPred, dfIndep1Test$LDLd)
```

###### Predict class of LDL
```{r}
drtXGBIndep1TestClassNCEP <- fClassNCEP(drtXGBIndep1TestRegrPred)
caret::confusionMatrix(dfIndep1Test$NCEPd, drtXGBIndep1TestClassNCEP)
drtXGBIndep1TestClassESC <- fClassESC(drtXGBIndep1TestRegrPred)
caret::confusionMatrix(dfIndep1Test$ESCd, drtXGBIndep1TestClassESC)
```

### Tune on Indep2 test data set
```{r, eval=F}
drtXGB_Indep2TrainRegr <- caret::train(form = LDLd ~ CHOL + TG + HDL,
                                   data = dfIndep2Train,
                                  method = "xgbDART")
```

### Load drtXGB_Indep2TrainRegr
```{r}
drtXGB_Indep2TrainRegr <-
  readRDS(file="./drtXGB_Indep2TrainRegr.rds")
```

#### Predict indep2 test
```{r}
drtXGBIndep2TestRegrPred <- predict(drtXGB_Indep2TrainRegr,
                                    newdata = dfIndep2Test)
drtXGBIndep2TestRegrSEE <- fSEE(drtXGBIndep2TestRegrPred, dfIndep2Test$LDLd)
```

###### Predict class of LDL
```{r}
drtXGBIndep2TestClassNCEP <- fClassNCEP(drtXGBIndep2TestRegrPred)
caret::confusionMatrix(dfIndep2Test$NCEPd, drtXGBIndep2TestClassNCEP)
drtXGBIndep2TestClassESC <- fClassESC(drtXGBIndep2TestRegrPred)
caret::confusionMatrix(dfIndep2Test$ESCd, drtXGBIndep2TestClassESC)
```

#### Vector of linear XGB regression SEE
```{r}
vecdrtXGB_RegrSEE <- round(c(drtXGBTestRegrSEE, drtXGBIndep1RegrSEE,
                             drtXGBIndep2RegrSEE,
                       drtXGB_Indep1TestRegrSEE, drtXGBIndep2RegrSEE), 1)
names(vecdrtXGB_RegrSEE) <- c("Test SEE", "Indep1 SEE on Train",
                              "Indep2 SEE on Train",
                             "Indep1 SEE",  "Indep2 SEE")
vecdrtXGB_RegrSEE
```

### Clean-up
```{r}
rm(list=ls(pattern="drtXGB*"))
rm(list=ls(pattern="vecdrtXGB*"))
```

# -----------------------
# 7. Neural network
##Regression
### Search for the network architecture that minimizes the MSE using 5-fold cross-validation
```{r, eval=F}
h2o.init(nthreads=-1)
h2o.no_progress()
vecNLayer <- seq(1,20)
vecNNodes <- seq(1,60)
size <- length(vecNLayer) * length(vecNNodes)
dfLDLdnn <- data.frame(nLayers=integer(size), nNodes=integer(size), MSE=numeric(size))
cnt <- 0
pb <- txtProgressBar(min = 0, max = size, style = 3, char="#")
  for(nLayer in 1:20) {# 20
      for(nNode in 1:60) {# 60
       cnt <- cnt + 1
       setTxtProgressBar(pb, cnt)
        vecHidden <- rep(vecNNodes[[nNode]], vecNLayer[[nLayer]])
        dfLDLdnn[cnt, 1:2] <- c(vecNLayer[[nLayer]], vecNNodes[[nNode]])
        tryCatch({
            dnnRes <- fDNNRegrGridSearch(DF=dfKomTrain, noOfFolds = 5,
                                         lstFolds = komTrainFolds,
                                         activation = "Rectifier",
                                         hiddenLayers = vecHidden)},
            error=function(e){})
        dfLDLdnn[cnt, 3] <- dnnRes
        cat(vecHidden, dnnRes, "\n")
      }
  }
h2o.shutdown(prompt = F)
write.table(dfLDLdnn, file="dfNCEPdnnCrVal_1_2.csv", sep=",", row.names = F)
```

```{r}
dfDnnRegr <- read.csv(file="./dfDnnRegr.csv", header=T, sep=",")
optimalDNN <- dfDnnRegr[which.min(dfDnnRegr$MSE), ]
```

The architecture of the DNN for which the mean squared error is min is 1 layers of 21 nodes.
In a previous iteration it was 3 layers of 29 nodes.

### Train the neural net with the above architecture (1 layer of 21 nodes) and predict the test data set. Then calculate the SEE.
```{r}
h2o.init(nthreads=-1)
dnnTrainRegr = h2o.deeplearning(y="LDLd",
                           training_frame =
                             as.h2o(dfKomTrain[ ,c("CHOLScaled", "HDLScaled",
                                                   "TGScaled", "LDLd")]),
                           activation = "Rectifier",
                           hidden = rep(21, 1), #c(nodes, layers)
                           epochs = 100,
                           train_samples_per_iteration = -2)
```

### Predict test data using train
```{r}
dnnTestRegrPred <-
  h2o.predict(dnnTrainRegr,
              newdata = as.h2o(dfKomTest[,c("CHOLScaled", "HDLScaled",
                                            "TGScaled")]))
dnnTestRegrPredSEE <- fSEE(dnnTestRegrPred, dfKomTest$LDLd)
```

#### Predict class of LDL
```{r}
dnnTestClassNCEP <- fClassNCEP(as.vector(dnnTestRegrPred))
caret::confusionMatrix(dfKomTest$NCEPd, dnnTestClassNCEP)
dnnTestClassESC <- fClassESC(as.vector(dnnTestRegrPred))
caret::confusionMatrix(dfKomTest$ESCd, dnnTestClassESC)
```

### Predict indep 1
```{r}
dnnIndep1RegrPred <-
  h2o.predict(dnnTrainRegr,
              newdata =as.h2o(dfIndep1[,c("CHOLScaled", "HDLScaled",
                                          "TGScaled")]))
dnnIndep1RegrPredSEE <- fSEE(dnnIndep1RegrPred, dfIndep1$LDLd)
```

#### Predict class of LDL
```{r}
dnnIndep1ClassNCEP <- fClassNCEP(as.vector(dnnIndep1RegrPred))
caret::confusionMatrix(dfIndep1$NCEPd, dnnIndep1ClassNCEP)
dnnIndep1ClassESC <- fClassESC(as.vector(dnnIndep1RegrPred))
caret::confusionMatrix(dfIndep1$ESCd, dnnIndep1ClassESC)
```

### Predict indep 2
```{r}
dnnIndep2RegrPred <- h2o.predict(dnnTrainRegr, newdata =
                                 as.h2o(dfIndep2[,c("CHOLScaled", "HDLScaled",
                                                    "TGScaled")]))
dnnIndep2RegrPredSEE <- fSEE(dnnIndep2RegrPred, dfIndep2$LDLd)
```

#### Predict class of LDL
```{r}
dnnIndep2ClassNCEP <- fClassNCEP(as.vector(dnnIndep2RegrPred))
caret::confusionMatrix(dfIndep2$NCEPd, dnnIndep2ClassNCEP)
dnnIndep2ClassESC <- fClassESC(as.vector(dnnIndep2RegrPred))
caret::confusionMatrix(dfIndep2$ESCd, dnnIndep2ClassESC)
```

### Clean up
```{r}
rm(list=ls(pattern="dnn*"))
rm(list=ls(pattern="vecDnn*"))
```

# ----------------------------------------
# 8. SEE versus JSD graph
```{r}
vcTrain <- c("Train", "Train", "Train", "Indep1Train", "Indep2Train")
vcTest <- c("Test", "Indep1", "Indep2", "Indep1Test", "Indep2Test")
vcJSD <- c(0.18, 0.66, 1.18, 0.87, 0.78)
vcRadSVM_SEE <- c(8.94, 10.10, 33.38, 11.00, 19.09)
#vcLinXGB_SEE <- c(9.19, 18.12, 23.74, 11.47, 23.74)
vcDartXGB_SEE <- c(8.52, 15.61, 20.96, 14.40, 20.96)
vcDNN_SEE <- c(8.37, 10.50, 34.61, NA, NA)
dfJSD_SEE <- cbind.data.frame(vcTrain, vcTest, vcJSD, 
  vcRadSVM_SEE, vcDartXGB_SEE, vcDNN_SEE)
colnames(dfJSD_SEE) <- c("TrainSet", "TestSet", "JSD", 
    "radSVM", "dartXGB", "DNN")
rm(vcTrain, vcTest, vcJSD,vcRadSVM_SEE, vcDartXGB_SEE, vcDNN_SEE)
dfJSD_SEE_long <- dfJSD_SEE %>% 
  pivot_longer(cols=-c("TrainSet", "TestSet", "JSD"),
               values_to="SEE") %>% 
  drop_na() %>% 
  arrange(JSD)
  
ggplot(data=dfJSD_SEE_long, aes(x=JSD, y=SEE)) +
  geom_line(aes(linetype=name), size=1) +
  geom_point(aes(shape=name), size=2) +
  xlab("Jensen-Shannon Divergence") +
  ylab("Standard Error of the Estimate") +
  geom_dl(aes(label = name), method =
                list(dl.combine("last.points"),
                  dl.trans(x=x-1, y=y)), cex = 0.8) +
    theme_classic() +
    theme(legend.position = "none",
          axis.title.x = element_text(size=14),
          axis.title.y = element_text(size=14),
          axis.text = element_text(size=14))
```

